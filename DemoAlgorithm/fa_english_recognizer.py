"""
FA English Recognizer - Nh·∫≠n di·ªán ti·∫øng Anh s·ª≠ d·ª•ng Finite Automata
B√†i to√°n: Ph√¢n bi·ªát chu·ªói ti·∫øng Anh t·ª´ t·∫°p √¢m (noise)
"""

from fa_models import DFA, NFA, EpsilonNFA
from fa_converter import FAConverter
from typing import Set, List, Dict, Tuple


class EnglishRecognizer:
    """
    M√°y nh·∫≠n di·ªán ti·∫øng Anh - Ph√¢n bi·ªát ti·∫øng Anh t·ª´ t·∫°p √¢m
    
    Chi·∫øn l∆∞·ª£c:
    1. T·∫°o Œµ-NFA ƒë·ªÉ nh·∫≠n d·∫°ng ti·∫øng Anh (linh ho·∫°t, d·ªÖ thi·∫øt k·∫ø)
    2. Chuy·ªÉn ƒë·ªïi th√†nh NFA (lo·∫°i b·ªè epsilon transitions)
    3. Chuy·ªÉn ƒë·ªïi th√†nh DFA (x√°c ƒë·ªãnh, nhanh ƒë·ªÉ ki·ªÉm tra)
    """
    
    @staticmethod
    def create_english_epsilon_nfa() -> EpsilonNFA:
        """
        T·∫°o Œµ-NFA nh·∫≠n di·ªán ti·∫øng Anh c∆° b·∫£n
        
        ƒê·ªãnh nghƒ©a ti·∫øng Anh:
        - Ch·ªâ ch·ª©a ch·ªØ c√°i (a-z, A-Z)
        - C√≥ th·ªÉ ch·ª©a kho·∫£ng tr·∫Øng gi·ªØa c√°c t·ª´
        - Kh√¥ng ch·ª©a ch·ªØ s·ªë ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát (tr·ª´ kho·∫£ng tr·∫Øng)
        
        V√≠ d·ª•:
        ‚úì "hello" - ti·∫øng Anh
        ‚úì "hello world" - ti·∫øng Anh
        ‚úó "hello123" - kh√¥ng ph·∫£i (c√≥ ch·ªØ s·ªë)
        ‚úó "h3llo" - kh√¥ng ph·∫£i (c√≥ ch·ªØ s·ªë)
        ‚úó "hello!" - kh√¥ng ph·∫£i (c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát)
        """
        e_nfa = EpsilonNFA()
        
        # C√°c tr·∫°ng th√°i
        e_nfa.add_state("q0", is_start=True)      # B·∫Øt ƒë·∫ßu
        e_nfa.add_state("q1")                      # ƒêang ƒë·ªçc t·ª´
        e_nfa.add_state("q2")                      # Sau t·ª´ (c√≥ th·ªÉ k·∫øt th√∫c ho·∫∑c kho·∫£ng tr·∫Øng)
        e_nfa.add_state("q3", is_accept=True)     # Tr·∫°ng th√°i k·∫øt th√∫c

        # Chuy·ªÉn ti·∫øp ch√≠nh
        # q0 -> q1: epsilon ƒë·ªÉ b·∫Øt ƒë·∫ßu ƒë·ªçc t·ª´ ƒë·∫ßu ti√™n
        e_nfa.add_epsilon_transition("q0", "q1")
        
        # q1: ƒê·ªçc ch·ªØ c√°i (a-z, A-Z)
        for letter in "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ":
            e_nfa.add_transition("q1", letter, "q1")  # Ti·∫øp t·ª•c ƒë·ªçc ch·ªØ c√°i
            e_nfa.add_transition("q1", letter, "q2")  # Ho·∫∑c chuy·ªÉn sang q2
        
        # q2: Sau khi ho√†n th√†nh m·ªôt t·ª´
        # - C√≥ th·ªÉ l√† t·ª´ cu·ªëi c√πng (chuy·ªÉn ƒë·∫øn q3 qua epsilon)
        e_nfa.add_epsilon_transition("q2", "q3")
        
        # - Ho·∫∑c c√≥ kho·∫£ng tr·∫Øng r·ªìi t·ª´ ti·∫øp theo
        e_nfa.add_transition("q2", " ", "q2")      # Kho·∫£ng tr·∫Øng li√™n ti·∫øp
        e_nfa.add_epsilon_transition("q2", "q1")   # Quay l·∫°i q1 ƒë·ªÉ ƒë·ªçc t·ª´ ti·∫øp theo
        
        # Alphabet
        e_nfa.alphabet = set("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ")
        
        return e_nfa
    
    @staticmethod
    def create_english_nfa() -> NFA:
        """
        Chuy·ªÉn ƒë·ªïi Œµ-NFA th√†nh NFA (lo·∫°i b·ªè epsilon transitions)
        
        Qu√° tr√¨nh:
        1. T√≠nh epsilon-closure cho m·ªói chuy·ªÉn ti·∫øp
        2. Chuy·ªÉn c√°c epsilon-transition th√†nh epsilon-closure
        3. C·∫≠p nh·∫≠t accept states d·ª±a tr√™n epsilon-closure
        """
        e_nfa = EnglishRecognizer.create_english_epsilon_nfa()
        nfa = FAConverter.epsilon_nfa_to_nfa(e_nfa)
        return nfa
    
    @staticmethod
    def create_english_dfa() -> DFA:
        """
        Chuy·ªÉn ƒë·ªïi NFA th√†nh DFA (Powerset Construction)
        
        Qu√° tr√¨nh:
        1. M·ªói tr·∫°ng th√°i DFA = t·∫≠p h·ª£p tr·∫°ng th√°i NFA
        2. B·∫Øt ƒë·∫ßu t·ª´ epsilon-closure c·ªßa q0
        3. V·ªõi m·ªói k√Ω t·ª±, t√≠nh t·∫≠p h·ª£p tr·∫°ng th√°i ti·∫øp theo
        
        L·ª£i √≠ch: DFA ch·∫°y O(n) trong khi NFA ch·∫°y O(n*m)
        """
        e_nfa = EnglishRecognizer.create_english_epsilon_nfa()
        dfa = FAConverter.epsilon_nfa_to_dfa(e_nfa)
        return dfa
    
    @staticmethod
    def is_english(text: str, use_dfa: bool = True) -> bool:
        """
        Ki·ªÉm tra xem chu·ªói c√≥ ph·∫£i ti·∫øng Anh kh√¥ng
        
        Args:
            text: Chu·ªói c·∫ßn ki·ªÉm tra
            use_dfa: S·ª≠ d·ª•ng DFA (nhanh) hay NFA (ch√≠nh x√°c)
        
        Returns:
            True n·∫øu l√† ti·∫øng Anh, False n·∫øu l√† t·∫°p √¢m
        """
        if use_dfa:
            dfa = EnglishRecognizer.create_english_dfa()
            return dfa.accepts_string(text)
        else:
            nfa = EnglishRecognizer.create_english_nfa()
            return nfa.accepts_string(text)
    
    @staticmethod
    def classify_strings(strings: List[str]) -> Tuple[List[str], List[str]]:
        """
        Ph√¢n lo·∫°i m·ªôt danh s√°ch chu·ªói th√†nh ti·∫øng Anh v√† t·∫°p √¢m
        
        Args:
            strings: Danh s√°ch chu·ªói h·ªón h·ª£p
        
        Returns:
            (english_strings, noise_strings)
        """
        english = []
        noise = []
        
        for s in strings:
            if EnglishRecognizer.is_english(s):
                english.append(s)
            else:
                noise.append(s)
        
        return english, noise
    
    @staticmethod
    def trace_english_recognition(text: str) -> Dict:
        """
        Theo d√µi qu√° tr√¨nh nh·∫≠n di·ªán ti·∫øng Anh
        
        Hi·ªÉn th·ªã:
        - C√°c chuy·ªÉn ti·∫øp qua c√°c tr·∫°ng th√°i
        - Epsilon-closure ·ªü m·ªói b∆∞·ªõc
        - K·∫øt qu·∫£ cu·ªëi c√πng
        """
        e_nfa = EnglishRecognizer.create_english_epsilon_nfa()
        dfa = EnglishRecognizer.create_english_dfa()
        
        result = {
            'text': text,
            'is_english_dfa': dfa.accepts_string(text),
            'is_english_nfa': e_nfa.accepts_string(text),
            'dfa_states': len(dfa.states),
            'e_nfa_states': len(e_nfa.states),
        }
        
        return result


class NoisyChannelSimulator:
    """
    M√¥ ph·ªèng k√™nh t·∫°p √¢m - sinh ra ti·∫øng Anh v√† t·∫°p √¢m h·ªón h·ª£p
    """
    
    @staticmethod
    def generate_english_strings(count: int = 10) -> List[str]:
        """Sinh ti·∫øng Anh ng·∫´u nhi√™n"""
        import random
        
        english_words = [
            "hello", "world", "python", "automata", "language", "machine",
            "learning", "theory", "computer", "science", "programming",
            "algorithm", "data", "structure", "network", "database",
            "security", "encryption", "digital", "information"
        ]
        
        result = []
        for _ in range(count):
            # Ch·ªçn 1-3 t·ª´ ng·∫´u nhi√™n
            num_words = random.randint(1, 3)
            sentence = " ".join(random.choices(english_words, k=num_words))
            result.append(sentence)
        
        return result
    
    @staticmethod
    def generate_noise_strings(count: int = 10) -> List[str]:
        """Sinh t·∫°p √¢m (chu·ªói kh√¥ng ph·∫£i ti·∫øng Anh)"""
        import random
        
        noise_patterns = [
            "12345",           # Ch·ªâ ch·ªØ s·ªë
            "abc123def",       # H·ªón h·ª£p ch·ªØ v√† s·ªë
            "hello@world",     # K√Ω t·ª± ƒë·∫∑c bi·ªát
            "üéÆüéØüé≤",         # Emoji
            "***###$$$",       # K√Ω t·ª± ƒë·∫∑c bi·ªát
            "h3ll0 w0rld",     # Ch·ªØ s·ªë thay ch·ªØ c√°i
            "caf√©",            # Ti·∫øng kh√¥ng ph·∫£i Anh
            "‰Ω†Â•Ω",            # Ti·∫øng Trung
            "ŸÖÿ±ÿ≠ÿ®ÿß",           # Ti·∫øng ·∫¢ R·∫≠p
            "–ø—Ä–∏–≤–µ—Ç",          # Ti·∫øng Nga
        ]
        
        result = []
        for _ in range(count):
            noise = random.choice(noise_patterns)
            result.append(noise)
        
        return result
    
    @staticmethod
    def create_noisy_channel(english_count: int = 10, noise_count: int = 10) -> List[Tuple[str, bool]]:
        """
        T·∫°o k√™nh t·∫°p √¢m: h·ªón h·ª£p ti·∫øng Anh v√† t·∫°p √¢m
        
        Returns:
            Danh s√°ch (chu·ªói, l√†_ti·∫øng_Anh)
        """
        import random
        
        english_strings = NoisyChannelSimulator.generate_english_strings(english_count)
        noise_strings = NoisyChannelSimulator.generate_noise_strings(noise_count)
        
        # T·∫°o danh s√°ch (chu·ªói, nh√£n)
        labeled = []
        for eng in english_strings:
            labeled.append((eng, True))
        for noise in noise_strings:
            labeled.append((noise, False))
        
        # X√°o tr·ªôn
        random.shuffle(labeled)
        
        return labeled


class EnglishRecognizerGame:
    """
    Game nh·∫≠n di·ªán ti·∫øng Anh
    
    Lu·∫≠t ch∆°i:
    - Hi·ªÉn th·ªã 20 chu·ªói h·ªón h·ª£p (ti·∫øng Anh + t·∫°p √¢m)
    - Ng∆∞·ªùi ch∆°i (ho·∫∑c DFA) ph·∫£i ph√¢n lo·∫°i ch√≠nh x√°c
    - T√≠nh ƒëi·ªÉm: s·ªë ƒë√∫ng / t·ªïng s·ªë
    """
    
    def __init__(self):
        self.score = 0
        self.total = 0
        self.channel = []
        self.results = []
    
    def start_game(self, english_count: int = 10, noise_count: int = 10):
        """B·∫Øt ƒë·∫ßu m·ªôt tr√≤ ch∆°i m·ªõi"""
        self.score = 0
        self.total = 0
        self.results = []
        
        # T·∫°o k√™nh t·∫°p √¢m
        self.channel = NoisyChannelSimulator.create_noisy_channel(english_count, noise_count)
        self.total = len(self.channel)
    
    def test_string(self, text: str) -> bool:
        """Ki·ªÉm tra m·ªôt chu·ªói"""
        result = EnglishRecognizer.is_english(text)
        return result
    
    def play_automated(self) -> float:
        """
        M√°y t·ª± ƒë·ªông ch∆°i - DFA ph√¢n lo·∫°i t·∫•t c·∫£
        
        Returns:
            T·ªâ l·ªá ch√≠nh x√°c (0-1)
        """
        if not self.channel:
            return 0.0
        
        for text, is_english_label in self.channel:
            predicted = EnglishRecognizer.is_english(text)
            
            if predicted == is_english_label:
                self.score += 1
                self.results.append({
                    'text': text,
                    'predicted': predicted,
                    'actual': is_english_label,
                    'correct': True
                })
            else:
                self.results.append({
                    'text': text,
                    'predicted': predicted,
                    'actual': is_english_label,
                    'correct': False
                })
        
        accuracy = self.score / self.total if self.total > 0 else 0
        return accuracy
    
    def get_report(self) -> str:
        """B√°o c√°o k·∫øt qu·∫£"""
        accuracy = self.score / self.total if self.total > 0 else 0
        
        report = f"""
{'='*60}
GAME REPORT - NH·∫¨N DI·ªÜN TI·∫æNG ANH
{'='*60}

ƒêi·ªÉm s·ªë: {self.score}/{self.total}
T·ªâ l·ªá ch√≠nh x√°c: {accuracy*100:.1f}%

Chi ti·∫øt:
"""
        
        for i, result in enumerate(self.results, 1):
            status = "‚úì" if result['correct'] else "‚úó"
            report += f"\n{i}. {status} '{result['text']}'\n"
            report += f"   D·ª± ƒëo√°n: {'TI·∫æNG ANH' if result['predicted'] else 'T·∫†P √ÇM'} | "
            report += f"Th·ª±c t·∫ø: {'TI·∫æNG ANH' if result['actual'] else 'T·∫†P √ÇM'}\n"
        
        report += f"\n{'='*60}\n"
        return report


# ============================================================================
# ADVANCED: Nh·∫≠n di·ªán ti·∫øng Anh n√¢ng cao v·ªõi t·ª´ ƒëi·ªÉn
# ============================================================================

class AdvancedEnglishRecognizer:
    """
    Nh·∫≠n di·ªán ti·∫øng Anh n√¢ng cao: s·ª≠ d·ª•ng t·ª´ ƒëi·ªÉn
    
    C·∫£i ti·∫øn:
    - Ki·ªÉm tra m·ªói t·ª´ trong t·ª´ ƒëi·ªÉn ti·∫øng Anh
    - H·ªó tr·ª£ ki·ªÉm tra ch√≠nh t·∫£
    - Lo·∫°i b·ªè ƒë∆∞·ª£c c√°c t·ª´ kh√¥ng h·ª£p l·ªá
    """
    
    # T·ª´ ƒëi·ªÉn ti·∫øng Anh ph·ªï bi·∫øn (c√≥ th·ªÉ m·ªü r·ªông)
    COMMON_WORDS = {
        "hello", "world", "python", "automata", "language", "machine",
        "learning", "theory", "computer", "science", "programming",
        "algorithm", "data", "structure", "network", "database",
        "security", "encryption", "digital", "information", "the", "is",
        "and", "to", "of", "in", "that", "have", "i", "it", "for",
        "not", "on", "with", "he", "as", "you", "do", "at", "this",
        "but", "his", "by", "from", "they", "we", "say", "her", "she",
        "or", "an", "will", "my", "one", "all", "would", "there", "their",
    }
    
    @staticmethod
    def is_valid_english_word(word: str) -> bool:
        """Ki·ªÉm tra t·ª´ c√≥ ph·∫£i ti·∫øng Anh kh√¥ng"""
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng
        word = word.strip().lower()
        
        # Ch·ªâ ch·ª©a ch·ªØ c√°i
        if not all(c.isalpha() or c == ' ' for c in word):
            return False
        
        # Kh√¥ng tr·ªëng
        if not word:
            return False
        
        # Ki·ªÉm tra t·ª´ ƒë∆°n l·∫ª
        words = word.split()
        for w in words:
            if w and w not in AdvancedEnglishRecognizer.COMMON_WORDS:
                # C√≥ th·ªÉ th√™m x·ª≠ l√Ω: t·ª´ kh√¥ng trong t·ª´ ƒëi·ªÉn nh∆∞ng c√≥ th·ªÉ l√† h·ª£p l·ªá
                # ·ªû ƒë√¢y c·ª©ng nh·∫°c ƒë·ªÉ demo
                pass
        
        return True
    
    @staticmethod
    def is_english_advanced(text: str) -> bool:
        """Ki·ªÉm tra ti·∫øng Anh n√¢ng cao"""
        # K·∫øt h·ª£p: DFA c∆° b·∫£n + ki·ªÉm tra t·ª´ ƒëi·ªÉn
        if not EnglishRecognizer.is_english(text):
            return False
        
        return AdvancedEnglishRecognizer.is_valid_english_word(text)


if __name__ == "__main__":
    print("="*70)
    print("ENGLISH RECOGNIZER - Nh·∫≠n di·ªán ti·∫øng Anh s·ª≠ d·ª•ng Finite Automata")
    print("="*70)
    
    # Demo 1: Ki·ªÉm tra chu·ªói ƒë∆°n
    print("\nüìù Demo 1: Ki·ªÉm tra chu·ªói ƒë∆°n")
    print("-" * 70)
    test_strings = [
        "hello",
        "hello world",
        "python",
        "hello123",
        "h3llo",
        "caf√©",
        "hello!",
        "PROGRAMMING",
        "test code",
        "abc@#$",
    ]
    
    for text in test_strings:
        result = EnglishRecognizer.is_english(text)
        status = "‚úì TI·∫æNG ANH" if result else "‚úó T·∫†P √ÇM"
        print(f"  '{text:20}' ‚Üí {status}")
    
    # Demo 2: Ph√¢n lo·∫°i chu·ªói h·ªón h·ª£p
    print("\nüìä Demo 2: Ph√¢n lo·∫°i chu·ªói h·ªón h·ª£p")
    print("-" * 70)
    mixed = ["hello world", "123456", "python code", "test@123", "machine learning"]
    english, noise = EnglishRecognizer.classify_strings(mixed)
    print(f"  Ti·∫øng Anh: {english}")
    print(f"  T·∫°p √¢m: {noise}")
    
    # Demo 3: Game nh·∫≠n di·ªán t·ª± ƒë·ªông
    print("\nüéÆ Demo 3: Game nh·∫≠n di·ªán t·ª± ƒë·ªông")
    print("-" * 70)
    game = EnglishRecognizerGame()
    game.start_game(english_count=5, noise_count=5)
    accuracy = game.play_automated()
    print(game.get_report())
    
    # Demo 4: So s√°nh DFA vs NFA
    print("üìä Demo 4: So s√°nh DFA vs NFA")
    print("-" * 70)
    e_nfa = EnglishRecognizer.create_english_epsilon_nfa()
    nfa = EnglishRecognizer.create_english_nfa()
    dfa = EnglishRecognizer.create_english_dfa()
    
    print(f"  Œµ-NFA: {len(e_nfa.states)} tr·∫°ng th√°i")
    print(f"  NFA:   {len(nfa.states)} tr·∫°ng th√°i")
    print(f"  DFA:   {len(dfa.states)} tr·∫°ng th√°i")
